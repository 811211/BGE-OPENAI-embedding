# ===========================================
# ğŸ“„ demo1
# åŠŸèƒ½ï¼šåŸºç¤æ¶æ§‹ ç”Ÿæˆå•é¡Œä¸¦æ¯”è¼ƒæ¨¡å‹
# ===========================================

import os
import psycopg2
import numpy as np
import faiss
from FlagEmbedding import BGEM3FlagModel
from tqdm import tqdm
from typing import List, Dict
from openai import AzureOpenAI
from dotenv import load_dotenv

# ----- ç’°å¢ƒé…ç½® -----
load_dotenv()

embedding_model = os.getenv("EMBEDDING_MODEL")

print("DEBUG: EMBEDDING_API_KEY =", os.getenv("EMBEDDING_API_KEY"))
print("DEBUG: EMBEDDING_URL =", os.getenv("EMBEDDING_URL"))
print("DEBUG: AOAI_API_VERSION =", os.getenv("AOAI_API_VERSION"))
print("DEBUG: EMBEDDING_MODEL =", os.getenv("EMBEDDING_MODEL"))
print("DEBUG: AOAI_CHAT_DEPLOYMENT =", os.getenv("AOAI_CHAT_DEPLOYMENT"))


# åˆå§‹åŒ– AzureOpenAI client
client = AzureOpenAI(
    api_key=os.getenv("AOAI_KEY"),
    azure_endpoint=os.getenv("AOAI_ENDPOINT"),
    api_version=os.getenv("AOAI_API_VERSION")
)

embedding_ada = AzureOpenAI(
    api_key=os.getenv("EMBEDDING_API_KEY"),
    azure_endpoint=os.getenv("EMBEDDING_URL"),
    api_version=os.getenv("AOAI_API_VERSION"),
)



BGE_MODEL = BGEM3FlagModel(
    r"C:\Users\user\.cache\huggingface\hub\models--BAAI--bge-m3\snapshots\5617a9f61b028005a4858fdac845db406aefb181",
    use_fp16=True
)

# ----- DB é€£ç·šåƒæ•¸ -----
DB_CONFIG = {
    "host": "210.67.12.103",
    "database": "Learning",
    "user": "editor",
    "password": "systex.6214",
    "port": 65432
}

# ----- æŠ½å–è³‡æ–™åº«æ–‡ä»¶ -----
def fetch_documents(limit=100) -> List[Dict]:
    max_chars = 2000  # æ¯æ¢è¨˜éŒ„çš„æœ€å¤§å­—ç¬¦æ•¸
    conn = psycopg2.connect(**DB_CONFIG)
    cur = conn.cursor()
    cur.execute('SELECT text FROM "2500567RAG2" LIMIT %s;', (limit,))
    docs = []
    for idx, row in enumerate(cur.fetchall()):
        text = row[0]
        # å®‰å…¨æª¢æŸ¥
        if not isinstance(text, str):
            print(f"âš ï¸ WARNING: é string è³‡æ–™ç™¼ç¾ï¼Œrow={row}")
            text = str(text)
        text = text.strip()[:max_chars]
        docs.append({"id": idx, "text": text})
    conn.close()
    return docs

    

# ----- ç”Ÿæˆå‡å•é¡Œ (Azure OpenAI ç‰ˆæœ¬) -----
def generate_questions_for_docs(docs: List[Dict], num_questions=1):
    questions = []
    chat_deployment = os.getenv("AOAI_API_VERSION")
    for doc in docs:
        prompt = f"è«‹æ ¹æ“šä»¥ä¸‹å…§å®¹ï¼Œç”Ÿæˆä¸€å€‹èˆ‡å…§å®¹æœ‰é—œçš„æ¸¬è©¦å•é¡Œï¼ˆä»¥ç¹é«”ä¸­æ–‡æè¿°ï¼‰ï¼š\n\n{doc['text']}\n\nå•é¡Œï¼š"
        try:
            response = client.chat.completions.create(
                model=chat_deployment,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.5,
                max_tokens=100
            )
            q = response.choices[0].message.content.strip()
            questions.append({"doc_id": doc["id"], "question": q})
        except Exception as e:
            print(f"ç”Ÿæˆå•é¡Œå‡ºéŒ¯ (AOAI): {e}")
    return questions

# ----- Embedding å‡½æ•¸ -----
def embed_openai(text: str) -> np.ndarray:
    if not isinstance(text, str):
        print(f"embed_openai è­¦å‘Š: text é strï¼Œå¯¦éš›é¡å‹ {type(text)}ï¼Œå€¼={text}")
        text = str(text)
    try:
        response = embedding_ada.embeddings.create(
            input=text,
            model=embedding_model
        )
        return np.array(response.data[0].embedding, dtype="float32")
    except Exception as e:
        print(f"embed_openai å‡ºéŒ¯: {e}")
        return np.zeros((1536,), dtype="float32")

def embed_bge(text: str) -> np.ndarray:
    if not isinstance(text, str):
        print(f"embed_bge è­¦å‘Š: text é strï¼Œå¯¦éš›é¡å‹ {type(text)}ï¼Œå€¼={text}")
        text = str(text)
    try:
        output = BGE_MODEL.encode(text)
        dense_vecs = output.get("dense_vecs")
        if dense_vecs is None:
            print(f"embed_bge è­¦å‘Š: dense_vecs ç‚ºç©ºï¼Œtext={text[:50]}...")
            return np.zeros((1024,), dtype="float32")
        # âœ… é€™è£¡ç›´æ¥ returnï¼Œä¸ç”¨å†å– [0]
        return dense_vecs.astype("float32")
    except Exception as e:
        print(f"embed_bge å‡ºéŒ¯: {e}")
        return np.zeros((1024,), dtype="float32")


# ----- å»ºç«‹ FAISS index -----
def build_faiss_index(vectors: List[np.ndarray]):
    dim = vectors[0].shape[0]
    index = faiss.IndexFlatL2(dim)
    index.add(np.vstack(vectors))
    return index

# ----- Pipeline ä¸»ç¨‹å¼ -----
def main():
    print("æŠ½å–è³‡æ–™ä¸­...")
    docs = fetch_documents(limit=50)
    print(f"å…±æŠ½å– {len(docs)} æ¢è³‡æ–™")

    print("ç”Ÿæˆå‡å•é¡Œ (AOAI)...")
    questions = generate_questions_for_docs(docs)

    print("è¨ˆç®— AOAI embedding...")
    vectors_openai = [embed_openai(doc["text"]) for doc in tqdm(docs)]

    print("è¨ˆç®— BGE embedding...")
    vectors_bge = [embed_bge(doc["text"]) for doc in tqdm(docs)]

    print("å»ºç«‹ FAISS index...")
    print(f"vectors_bge é•·åº¦ = {len(vectors_bge)}")
    for idx, vec in enumerate(vectors_bge):
        print(f"ç¬¬ {idx} å€‹ vector shape = {vec.shape} dtype={vec.dtype}")

    index_openai = build_faiss_index(vectors_openai)
    index_bge = build_faiss_index(vectors_bge)

    print("é–‹å§‹è©•ä¼°...")
    k = 1
    correct_openai = 0
    correct_bge = 0

    for q in tqdm(questions):
        try:
            q_vec_openai = embed_openai(q["question"])
            q_vec_bge = embed_bge(q["question"])

            D_openai, I_openai = index_openai.search(q_vec_openai.reshape(1, -1), k)
            D_bge, I_bge = index_bge.search(q_vec_bge.reshape(1, -1), k)

            doc_idx = next(i for i, d in enumerate(docs) if d["id"] == q["doc_id"])
            
            if doc_idx in I_openai[0]:
                correct_openai += 1
            if doc_idx in I_bge[0]:
                correct_bge += 1
        except Exception as e:
            print(f"è©•ä¼°æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    acc_openai = correct_openai / len(questions) if questions else 0
    acc_bge = correct_bge / len(questions) if questions else 0

    print(f"AOAI embedding æª¢ç´¢æ­£ç¢ºç‡: {acc_openai:.2f}")
    print(f"BGE embedding æª¢ç´¢æ­£ç¢ºç‡: {acc_bge:.2f}")

if __name__ == "__main__":
    
    # test_text = "<è‡ªç‡Ÿå•†è²·è¶…30-11>ç¢³é«˜æ¯(439),é‡‘ å¯¶(387),çŸ½ å‰µ(37) ..."
    # print(f"æ¸¬è©¦æ–‡æœ¬: {test_text[:50]}...")

    # vec = embed_openai(test_text)
    # print(f"Embedding å‘é‡ shape: {vec.shape}")
    # print(f"Embedding å‰ 5 ç¶­: {vec[:5]}")
    
    # test_text = "<è‡ªç‡Ÿå•†è²·è¶…30-11>ç¢³é«˜æ¯(439),é‡‘ å¯¶(387),çŸ½ å‰µ(37)..."
    # print(f"æ¸¬è©¦æ–‡æœ¬: {test_text[:50]}...")
    # vec = embed_bge(test_text)
    # print(f"Embedding å‘é‡ shape: {vec.shape}")
    # print(f"Embedding å‰ 5 ç¶­: {vec[:5]}")


    main()
